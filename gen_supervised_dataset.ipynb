{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "from gym_kidney import _solver\n",
    "from gym.utils import seeding\n",
    "from gym_kidney import models\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First: generate graphs somehow, according to the models.\n",
    "\n",
    "One dumb idea, give some a long number of ticks and others a short number of ticks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _default_model():\n",
    "    M = 128\n",
    "    K = 1024\n",
    "    K = 580\n",
    "    P = 0.05\n",
    "    P_A = 0.05\n",
    "    LEN = 3*K\n",
    "    MODEL = models.HomogeneousModel(M, K, P, P_A, LEN)\n",
    "    return MODEL\n",
    "\n",
    "DEFAULT_MODEL = _default_model()\n",
    "\n",
    "rng, seed = seeding.np_random(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_random_graph(model, rng, n_steps=300):\n",
    "    G = nx.DiGraph()\n",
    "    for i in range(n_steps):\n",
    "        G = model.arrive(G,rng)\n",
    "    return G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def relabel(G):\n",
    "    n_dd, n_ndd = 0, 0\n",
    "    d_dd, d_ndd = {}, {}\n",
    "\n",
    "    for u in G.nodes():\n",
    "        if G.node[u][\"ndd\"]:\n",
    "            d_ndd[u] = n_ndd\n",
    "            n_ndd += 1\n",
    "        else:\n",
    "            d_dd[u] = n_dd\n",
    "            n_dd += 1\n",
    "\n",
    "    return n_dd, n_ndd, d_dd, d_ndd\n",
    "\n",
    "def nx_to_ks(G):\n",
    "    n_dd, n_ndd, d_dd, d_ndd = relabel(G)\n",
    "\n",
    "    dd = _solver.Digraph(n_dd)\n",
    "    for u, v, d in G.edges(data = True):\n",
    "        if not G.node[u][\"ndd\"]:\n",
    "            dd.add_edge(\n",
    "                d[\"weight\"] if (\"weight\" in d) else 1.0,\n",
    "                dd.vs[d_dd[u]],\n",
    "                dd.vs[d_dd[v]])\n",
    "\n",
    "    ndds = [_solver.kidney_ndds.Ndd() for _ in range(n_ndd)]\n",
    "    for u, v, d in G.edges(data = True):\n",
    "        if G.node[u][\"ndd\"]:\n",
    "            edge = _solver.kidney_ndds.NddEdge(\n",
    "                dd.vs[d_dd[v]],\n",
    "                d[\"weight\"] if (\"weight\" in d) else 1.0)\n",
    "            ndds[d_ndd[u]].add_edge(edge)\n",
    "\n",
    "    return dd, ndds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def solve_graph(G, cycle_cap=3, chain_cap=3):\n",
    "    dd, ndd = nx_to_ks(G)\n",
    "    cfg = _solver.kidney_ip.OptConfig(\n",
    "            dd,\n",
    "            ndd,\n",
    "            cycle_cap,\n",
    "            chain_cap)\n",
    "    soln  = _solver.solve_kep(cfg, \"picef\")\n",
    "    rew_cycles = sum(map(lambda x: len(x), soln.cycles))\n",
    "    rew_chains = sum(map(lambda x: len(x.vtx_indices), soln.chains))\n",
    "    reward = rew_cycles + rew_chains\n",
    "    \n",
    "    return reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_graph_score_pair(rng):\n",
    "    gr = gen_random_graph(DEFAULT_MODEL, rng)\n",
    "    score = solve_graph(gr)\n",
    "    return (gr, score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/1000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Academic license - for non-commercial use only\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:10<00:00, 98.67it/s]\n",
      "100%|██████████| 100/100 [00:00<00:00, 103.10it/s]\n"
     ]
    }
   ],
   "source": [
    "dataset = [make_graph_score_pair(rng) for _ in tqdm(range(1000))]\n",
    "validation_set = [make_graph_score_pair(rng) for _ in tqdm(range(100))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adjmat(gr):\n",
    "    return nx.adjacency_matrix(gr).toarray().astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def zero_padded_adjmat(graph, size):\n",
    "    unpadded = adjmat(graph)\n",
    "    padded = np.zeros((size, size))\n",
    "    padded[0:unpadded.shape[0], 0:unpadded.shape[1]] = unpadded\n",
    "    padded = np.reshape(padded, (padded.shape[0], padded.shape[1], 1))\n",
    "    return padded\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.keras\n",
    "from tensorflow.keras.layers import Input, Dense, Dropout, Flatten, MaxPooling2D, Conv2D\n",
    "from tensorflow.keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.contrib.eager as tfe\n",
    "tf.enable_eager_execution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def single_s2v_iter(adjmat, prev_embeddings, theta2):\n",
    "    sum_neighbor_rows = adjmat @ prev_embeddings\n",
    "    return tf.nn.relu(sum_neighbor_rows * theta2)\n",
    "\n",
    "def s2v_four_times(adjmat, initial_embeddings, theta2):\n",
    "    curr_embed = single_s2v_iter(adjmat, initial_embeddings, theta2)\n",
    "    for i in range(3):\n",
    "        curr_embed = single_s2v_iter(adjmat, curr_embed, theta2)\n",
    "    return curr_embed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_adjmat = tf.constant(zero_padded_adjmat(dataset[0][0], 70).squeeze().astype('float32'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "init_embed = tf.constant(np.random.rand(70,10).astype('float32'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_theta = tfe.Variable(np.random.rand(70,1).astype('float32'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = s2v_four_times(example_adjmat, init_embed, example_theta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=76, shape=(70, 10), dtype=float32, numpy=\n",
       "array([[3.81191254e-01, 3.21447492e-01, 3.07930678e-01, 3.38622838e-01,\n",
       "        3.09505343e-01, 3.81596655e-01, 3.20657939e-01, 3.24535728e-01,\n",
       "        3.14646631e-01, 3.44594151e-01],\n",
       "       [6.23087943e-01, 5.94693005e-01, 5.55782914e-01, 5.58918953e-01,\n",
       "        4.75298136e-01, 5.82949579e-01, 5.07556975e-01, 5.80697477e-01,\n",
       "        5.49205184e-01, 5.32512784e-01],\n",
       "       [9.67614427e-02, 9.64296609e-02, 7.11854249e-02, 9.49467272e-02,\n",
       "        6.76327273e-02, 9.29112062e-02, 8.41771215e-02, 8.57844204e-02,\n",
       "        8.37598220e-02, 8.91274065e-02],\n",
       "       [4.45059799e-02, 1.09183297e-01, 6.12500310e-02, 4.35574464e-02,\n",
       "        1.21288700e-02, 9.26394910e-02, 1.65374890e-01, 1.68280318e-01,\n",
       "        1.58647150e-01, 1.08317949e-01],\n",
       "       [1.08982623e-01, 1.08248077e-01, 8.04215446e-02, 1.23802654e-01,\n",
       "        9.60175097e-02, 1.10320829e-01, 6.91889375e-02, 1.55001819e-01,\n",
       "        7.93061703e-02, 5.04395738e-02],\n",
       "       [7.06837463e+00, 5.55273533e+00, 6.11310291e+00, 6.88826418e+00,\n",
       "        5.61287689e+00, 6.76550341e+00, 5.69828701e+00, 6.25928497e+00,\n",
       "        5.66913414e+00, 6.75699043e+00],\n",
       "       [2.29276967e+00, 2.38225842e+00, 2.27461672e+00, 2.67161274e+00,\n",
       "        2.87382650e+00, 2.96104884e+00, 2.19514513e+00, 3.06364489e+00,\n",
       "        2.61757612e+00, 2.69168377e+00],\n",
       "       [4.87685776e+00, 5.50930023e+00, 4.74911118e+00, 6.02930021e+00,\n",
       "        5.39838886e+00, 6.44210243e+00, 4.95354080e+00, 5.76894188e+00,\n",
       "        5.05873489e+00, 5.74524641e+00],\n",
       "       [2.26686895e-01, 2.76997626e-01, 2.24353135e-01, 1.88991129e-01,\n",
       "        2.04606920e-01, 2.53234118e-01, 2.10743010e-01, 1.97058991e-01,\n",
       "        2.11493030e-01, 2.15741128e-01],\n",
       "       [1.93902552e-01, 1.24695219e-01, 9.13282558e-02, 1.82293177e-01,\n",
       "        6.66764155e-02, 1.99695393e-01, 1.88991249e-01, 1.65850535e-01,\n",
       "        1.58026636e-01, 1.00813054e-01],\n",
       "       [2.11790144e-01, 1.41624510e-01, 1.00596882e-01, 1.65338337e-01,\n",
       "        1.12617284e-01, 1.94904953e-01, 1.95383966e-01, 1.72578052e-01,\n",
       "        1.71054751e-01, 1.45448938e-01],\n",
       "       [1.32059062e+00, 1.08910310e+00, 1.06817865e+00, 1.27974236e+00,\n",
       "        1.28292811e+00, 1.37544835e+00, 1.10174119e+00, 1.30009520e+00,\n",
       "        1.17821050e+00, 1.32052898e+00],\n",
       "       [6.14494467e+00, 5.41117096e+00, 5.45682716e+00, 6.50897455e+00,\n",
       "        6.46168661e+00, 6.55414724e+00, 4.92275429e+00, 6.67342710e+00,\n",
       "        5.93742657e+00, 5.89474678e+00],\n",
       "       [1.39252767e-01, 1.42706752e-01, 1.27512813e-01, 1.49849147e-01,\n",
       "        1.15989625e-01, 1.21033512e-01, 1.46701068e-01, 1.73321843e-01,\n",
       "        1.66755199e-01, 1.66547984e-01],\n",
       "       [4.88679171e+00, 4.49997663e+00, 4.22900963e+00, 5.57372618e+00,\n",
       "        4.49800682e+00, 5.48626900e+00, 4.93968773e+00, 5.07641411e+00,\n",
       "        4.71226168e+00, 5.40951109e+00],\n",
       "       [2.09976360e-02, 2.05706134e-02, 1.80429649e-02, 2.13897005e-02,\n",
       "        2.15302166e-02, 2.36532353e-02, 1.71074178e-02, 2.30629258e-02,\n",
       "        1.83039885e-02, 1.78154483e-02],\n",
       "       [5.56822109e+00, 6.31594515e+00, 5.17573404e+00, 6.59046364e+00,\n",
       "        5.60426426e+00, 6.82424498e+00, 5.62628412e+00, 5.91575861e+00,\n",
       "        5.77404213e+00, 6.49242592e+00],\n",
       "       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00],\n",
       "       [2.81944084e+00, 2.58315659e+00, 2.62823510e+00, 2.80593300e+00,\n",
       "        2.13753414e+00, 2.87638545e+00, 2.21405959e+00, 2.52478456e+00,\n",
       "        2.28455567e+00, 2.57355762e+00],\n",
       "       [2.74421901e-01, 2.15692207e-01, 2.46297106e-01, 3.43561977e-01,\n",
       "        3.18395615e-01, 3.11636776e-01, 2.12106586e-01, 2.98093438e-01,\n",
       "        2.03636810e-01, 2.63279378e-01],\n",
       "       [2.53215766e+00, 2.99126744e+00, 2.65082216e+00, 3.17587972e+00,\n",
       "        2.88026166e+00, 3.07786918e+00, 2.76637101e+00, 3.53442001e+00,\n",
       "        3.25889874e+00, 2.93470573e+00],\n",
       "       [6.04033582e-02, 7.04338700e-02, 6.08907007e-02, 8.22655335e-02,\n",
       "        7.23550320e-02, 8.01490247e-02, 7.02857897e-02, 9.69610140e-02,\n",
       "        1.03246905e-01, 8.69423822e-02],\n",
       "       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00],\n",
       "       [1.39485383e+00, 7.74399042e-01, 9.57464516e-01, 1.24926662e+00,\n",
       "        1.14492762e+00, 1.10854948e+00, 1.02073729e+00, 1.22316909e+00,\n",
       "        1.04029679e+00, 1.26723754e+00],\n",
       "       [6.08846283e+00, 6.69152498e+00, 5.57606936e+00, 7.16937160e+00,\n",
       "        6.24144888e+00, 7.93191195e+00, 5.90631914e+00, 6.67336750e+00,\n",
       "        5.89304590e+00, 6.90225315e+00],\n",
       "       [6.92195892e-01, 6.44281983e-01, 5.70950449e-01, 6.32899165e-01,\n",
       "        4.69798416e-01, 6.80461407e-01, 6.12077713e-01, 7.01565683e-01,\n",
       "        6.62605345e-01, 5.56790292e-01],\n",
       "       [9.46349129e-02, 7.83272013e-02, 8.96645486e-02, 9.20471400e-02,\n",
       "        7.31256604e-02, 9.45514441e-02, 7.50715733e-02, 8.39961395e-02,\n",
       "        8.51683170e-02, 8.12652260e-02],\n",
       "       [6.11352548e-03, 1.57977715e-02, 1.12112174e-02, 3.73048708e-03,\n",
       "        5.48997195e-03, 1.43633289e-02, 1.41758192e-02, 2.15466861e-02,\n",
       "        1.85710192e-02, 1.02165723e-02],\n",
       "       [3.43980730e-01, 2.94955641e-01, 2.76419520e-01, 3.15751821e-01,\n",
       "        2.30718791e-01, 3.22456092e-01, 2.85083741e-01, 3.28030288e-01,\n",
       "        3.08145940e-01, 2.54488766e-01],\n",
       "       [3.16346836e+00, 3.55189633e+00, 3.14836383e+00, 3.86850762e+00,\n",
       "        3.27480483e+00, 3.78738093e+00, 3.35685325e+00, 3.86085963e+00,\n",
       "        3.65445614e+00, 3.64074135e+00],\n",
       "       [5.80656910e+00, 4.43029451e+00, 4.75715923e+00, 5.79898882e+00,\n",
       "        5.64500761e+00, 5.93221426e+00, 4.55338287e+00, 5.80132723e+00,\n",
       "        4.83162308e+00, 5.35784960e+00],\n",
       "       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00],\n",
       "       [1.26614988e-01, 2.21801743e-01, 2.15436295e-01, 1.92492694e-01,\n",
       "        2.05179125e-01, 2.29351655e-01, 2.42789879e-01, 1.31356210e-01,\n",
       "        2.04011858e-01, 2.18055263e-01],\n",
       "       [5.86421204e+00, 5.50200987e+00, 5.50213289e+00, 6.13133240e+00,\n",
       "        5.27218294e+00, 6.47473717e+00, 4.86321640e+00, 5.92980099e+00,\n",
       "        5.23613358e+00, 5.67708635e+00],\n",
       "       [2.01279688e+00, 2.20545030e+00, 1.97991395e+00, 1.96646821e+00,\n",
       "        2.20943213e+00, 2.03320217e+00, 1.86921453e+00, 2.31864905e+00,\n",
       "        2.46148968e+00, 2.28566051e+00],\n",
       "       [4.65711498e+00, 4.64315176e+00, 4.10879850e+00, 4.06039762e+00,\n",
       "        3.49496198e+00, 4.52353048e+00, 4.13824987e+00, 4.59182119e+00,\n",
       "        4.48391676e+00, 3.68025923e+00],\n",
       "       [8.41898322e-01, 6.46448612e-01, 6.38730764e-01, 6.64687932e-01,\n",
       "        6.80860400e-01, 6.70400620e-01, 6.85711265e-01, 6.48945332e-01,\n",
       "        6.99829757e-01, 6.66650474e-01],\n",
       "       [4.51593623e-02, 3.60398218e-02, 3.81655134e-02, 3.57754678e-02,\n",
       "        4.03329395e-02, 3.42541374e-02, 3.52945402e-02, 3.42033021e-02,\n",
       "        3.78634557e-02, 3.72051634e-02],\n",
       "       [2.62169766e+00, 2.79403830e+00, 2.37413216e+00, 3.22625947e+00,\n",
       "        2.45967150e+00, 3.20001531e+00, 2.80278802e+00, 2.84270477e+00,\n",
       "        2.71612024e+00, 2.99747372e+00],\n",
       "       [3.72002482e-01, 3.45780611e-01, 3.11764657e-01, 3.31014901e-01,\n",
       "        3.44083518e-01, 3.98447305e-01, 3.14072460e-01, 3.45786929e-01,\n",
       "        3.38708103e-01, 3.58678430e-01],\n",
       "       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00],\n",
       "       [3.07272291e+00, 2.40652251e+00, 2.45227122e+00, 3.07249618e+00,\n",
       "        3.13467622e+00, 3.31510901e+00, 2.60231400e+00, 3.14458513e+00,\n",
       "        2.65221453e+00, 3.05807233e+00],\n",
       "       [7.22575366e-01, 8.02875102e-01, 6.67875707e-01, 8.28584135e-01,\n",
       "        7.29448617e-01, 9.17997718e-01, 8.47416699e-01, 1.07298648e+00,\n",
       "        1.09440219e+00, 9.15655673e-01],\n",
       "       [1.19392169e+00, 1.46775746e+00, 1.35001194e+00, 1.78201771e+00,\n",
       "        1.36350703e+00, 1.55206704e+00, 1.44957447e+00, 1.50214636e+00,\n",
       "        1.36501515e+00, 1.65993941e+00],\n",
       "       [2.58319283e+00, 3.07679701e+00, 2.74571514e+00, 3.25575852e+00,\n",
       "        2.97273302e+00, 3.16718197e+00, 2.88355207e+00, 3.60210562e+00,\n",
       "        3.39965391e+00, 3.08729434e+00],\n",
       "       [8.30463469e-01, 6.07442081e-01, 6.98781550e-01, 7.39529908e-01,\n",
       "        6.06677353e-01, 7.26873636e-01, 6.75663948e-01, 6.87815964e-01,\n",
       "        7.86379874e-01, 7.80965388e-01],\n",
       "       [5.96900322e-02, 6.78734407e-02, 5.40945269e-02, 5.01126796e-02,\n",
       "        4.95403707e-02, 6.37350380e-02, 5.28695248e-02, 4.94702905e-02,\n",
       "        5.28067537e-02, 5.52559048e-02],\n",
       "       [2.43074965e+00, 2.21853757e+00, 2.05664253e+00, 2.56752062e+00,\n",
       "        2.35622978e+00, 2.61982322e+00, 2.02107954e+00, 2.43059778e+00,\n",
       "        2.17040277e+00, 2.37311363e+00],\n",
       "       [1.34025383e+00, 1.38604498e+00, 1.07590353e+00, 1.44800246e+00,\n",
       "        1.28825736e+00, 1.49187851e+00, 1.19020057e+00, 1.32319462e+00,\n",
       "        1.24976242e+00, 1.40487850e+00],\n",
       "       [5.39701796e+00, 4.97421074e+00, 4.77639055e+00, 6.05901909e+00,\n",
       "        5.01832581e+00, 5.89499664e+00, 5.28298759e+00, 5.54370642e+00,\n",
       "        5.15274000e+00, 5.86616230e+00],\n",
       "       [5.42992532e-01, 4.50127751e-01, 5.14856756e-01, 5.24096668e-01,\n",
       "        4.17769313e-01, 5.51058412e-01, 4.29506034e-01, 4.82728511e-01,\n",
       "        4.88065451e-01, 4.54415113e-01],\n",
       "       [9.46560055e-02, 8.73532295e-02, 6.64375648e-02, 9.65025350e-02,\n",
       "        6.50268868e-02, 1.04244202e-01, 8.92621204e-02, 9.88157243e-02,\n",
       "        8.44850987e-02, 7.08998442e-02],\n",
       "       [2.68843055e+00, 2.75526953e+00, 2.95811605e+00, 3.22529674e+00,\n",
       "        2.46253347e+00, 2.88198471e+00, 2.59132338e+00, 2.82245755e+00,\n",
       "        2.63603973e+00, 3.01664329e+00],\n",
       "       [8.86891305e-01, 6.41891599e-01, 8.11453104e-01, 1.15762317e+00,\n",
       "        1.13272130e+00, 1.02760839e+00, 6.48486197e-01, 1.01593506e+00,\n",
       "        6.32984221e-01, 8.24289501e-01],\n",
       "       [2.51355004e+00, 1.75965118e+00, 2.04531002e+00, 1.77956033e+00,\n",
       "        1.69708002e+00, 1.67972517e+00, 1.98500657e+00, 1.71514630e+00,\n",
       "        2.05033731e+00, 2.10341835e+00],\n",
       "       [3.02833414e+00, 2.37223005e+00, 2.51779771e+00, 3.34890652e+00,\n",
       "        2.75987530e+00, 3.00793695e+00, 3.02193093e+00, 3.14801574e+00,\n",
       "        2.82562685e+00, 3.43495631e+00],\n",
       "       [1.68059960e-01, 1.62294418e-01, 1.53767124e-01, 1.94745138e-01,\n",
       "        1.71116546e-01, 1.97681755e-01, 1.50773004e-01, 1.80095345e-01,\n",
       "        1.57837659e-01, 1.74964353e-01],\n",
       "       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00],\n",
       "       [7.48198128e+00, 7.03539038e+00, 6.71031761e+00, 8.26549149e+00,\n",
       "        6.04703379e+00, 7.72619677e+00, 7.18773842e+00, 7.62609148e+00,\n",
       "        6.93039751e+00, 7.34646702e+00],\n",
       "       [5.62860632e+00, 4.97360134e+00, 5.01455498e+00, 4.82886362e+00,\n",
       "        4.83223009e+00, 4.87493420e+00, 4.79255009e+00, 5.13928413e+00,\n",
       "        5.63624477e+00, 5.37190199e+00],\n",
       "       [4.11950260e-01, 2.76431561e-01, 2.22147673e-01, 3.09745818e-01,\n",
       "        2.31521428e-01, 2.98785716e-01, 3.82543206e-01, 3.03383529e-01,\n",
       "        4.02643412e-01, 4.24822956e-01],\n",
       "       [1.41404295e+00, 1.32090783e+00, 1.26943207e+00, 1.42415643e+00,\n",
       "        9.97920334e-01, 1.42279565e+00, 1.27253652e+00, 1.35583127e+00,\n",
       "        1.29956782e+00, 1.26115394e+00],\n",
       "       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00],\n",
       "       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00],\n",
       "       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00],\n",
       "       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00],\n",
       "       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00],\n",
       "       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00],\n",
       "       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00],\n",
       "       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00]], dtype=float32)>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "class S2VLayer(tensorflow.keras.layers.Layer):\n",
    "    def __init__(self, embedding_dim, **kwargs):\n",
    "        self.embedding_dim = embedding_dim\n",
    "        super(S2VLayer, self).__init__(**kwargs)\n",
    "    \n",
    "    def build(self, input_shape):\n",
    "        self.theta2 = self.add_weight(name='theta2', shape=(input_shape[0],1), initializer='uniform', trainable=True)\n",
    "        self.initial_embeddings = self.add_weight(name='init_theta', shape=(input_shape[0], self.embedding_dim), initializer='uniform', trainable=False)\n",
    "        super(S2VLayer, self).build(input_shape)\n",
    "        \n",
    "    def call(self, adjmat):\n",
    "        return s2v_four_times(adjmat, self.initial_embeddings, self.theta2)\n",
    "    \n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return (input_shape[0], self.embedding_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "xx = S2VLayer(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "here are some ineffective neural network models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mlp_model(input_size=100):\n",
    "    input_im = Input(shape=(input_size, input_size, 1)) # may as well be compatible with cnn\n",
    "    flat = Flatten()(input_im)\n",
    "    l1 = Dense(100, activation='relu')(flat)\n",
    "    l2 = Dense(20, activation='relu')(l1)\n",
    "    output = Dense(1, activation='relu')(l2)\n",
    "    mlp_model = Model(input_im, output)\n",
    "    return mlp_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cnn_model(input_size=100):\n",
    "    input_im = Input(shape=(input_size, input_size,1))\n",
    "    layer = Conv2D(32, (3, 3), activation='relu', padding='same')(input_im)\n",
    "    layer = MaxPooling2D((2, 2), padding='same')(layer)\n",
    "    layer = Conv2D(16, (3, 3), activation='relu', padding='same')(layer)\n",
    "    layer = MaxPooling2D((2, 2), padding='same')(layer)\n",
    "    layer = Conv2D(16, (3, 3), activation='relu', padding='same')(layer)\n",
    "    layer = MaxPooling2D((2, 2), padding='same')(layer)\n",
    "    layer = Flatten()(layer)\n",
    "    layer = Dense(32, activation='relu')(layer)\n",
    "    output = Dense(1, activation='relu')(layer)\n",
    "    cnn_model = Model(input_im, output)\n",
    "    return cnn_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 100, 100, 1)       0         \n",
      "_________________________________________________________________\n",
      "conv2d (Conv2D)              (None, 100, 100, 32)      320       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 50, 50, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 50, 50, 16)        4624      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 25, 25, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 25, 25, 16)        2320      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 13, 13, 16)        0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 2704)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 32)                86560     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 93,857\n",
      "Trainable params: 93,857\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "cnn_model().summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         (None, 100, 100, 1)       0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 10000)             0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 100)               1000100   \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 20)                2020      \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1)                 21        \n",
      "=================================================================\n",
      "Total params: 1,002,141\n",
      "Trainable params: 1,002,141\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "mlp_model().summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_mats = np.stack([zero_padded_adjmat(g, 100) for g, _ in dataset])\n",
    "graph_scores = np.expand_dims(np.stack([x for _, x in dataset]), axis=1).astype('float32')\n",
    "\n",
    "val_mats = np.stack([zero_padded_adjmat(g, 100) for g, _ in validation_set])\n",
    "val_scores = np.expand_dims(np.stack([x for _, x in validation_set]), axis=1).astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 10000 samples, validate on 1000 samples\n",
      "Epoch 1/50\n",
      "10000/10000 [==============================] - 1s 67us/step - loss: 79.6723 - val_loss: 34.2367\n",
      "Epoch 2/50\n",
      "10000/10000 [==============================] - 0s 40us/step - loss: 31.0945 - val_loss: 35.4946\n",
      "Epoch 3/50\n",
      "10000/10000 [==============================] - 0s 41us/step - loss: 27.1537 - val_loss: 40.9094\n",
      "Epoch 4/50\n",
      "10000/10000 [==============================] - 0s 41us/step - loss: 23.8659 - val_loss: 41.9874\n",
      "Epoch 5/50\n",
      "10000/10000 [==============================] - 0s 41us/step - loss: 18.0754 - val_loss: 47.8495\n",
      "Epoch 6/50\n",
      "10000/10000 [==============================] - 0s 41us/step - loss: 12.2546 - val_loss: 50.8657\n",
      "Epoch 7/50\n",
      "10000/10000 [==============================] - 0s 41us/step - loss: 9.5404 - val_loss: 51.3274\n",
      "Epoch 8/50\n",
      "10000/10000 [==============================] - 0s 42us/step - loss: 9.3253 - val_loss: 58.3344\n",
      "Epoch 9/50\n",
      "10000/10000 [==============================] - 0s 41us/step - loss: 8.1976 - val_loss: 46.2212\n",
      "Epoch 10/50\n",
      "10000/10000 [==============================] - 0s 41us/step - loss: 7.8441 - val_loss: 46.2443\n",
      "Epoch 11/50\n",
      "10000/10000 [==============================] - 0s 41us/step - loss: 7.1912 - val_loss: 47.5968\n",
      "Epoch 12/50\n",
      "10000/10000 [==============================] - 0s 41us/step - loss: 5.3722 - val_loss: 64.2285\n",
      "Epoch 13/50\n",
      "10000/10000 [==============================] - 0s 42us/step - loss: 6.8320 - val_loss: 59.6221\n",
      "Epoch 14/50\n",
      "10000/10000 [==============================] - 0s 41us/step - loss: 5.9355 - val_loss: 46.5091\n",
      "Epoch 15/50\n",
      "10000/10000 [==============================] - 0s 41us/step - loss: 5.3262 - val_loss: 58.0585\n",
      "Epoch 16/50\n",
      "10000/10000 [==============================] - 0s 41us/step - loss: 5.6258 - val_loss: 58.1062\n",
      "Epoch 17/50\n",
      "10000/10000 [==============================] - 0s 41us/step - loss: 4.9626 - val_loss: 47.9548\n",
      "Epoch 18/50\n",
      "10000/10000 [==============================] - 0s 41us/step - loss: 4.8155 - val_loss: 46.1798\n",
      "Epoch 19/50\n",
      "10000/10000 [==============================] - 0s 41us/step - loss: 4.2920 - val_loss: 52.7111\n",
      "Epoch 20/50\n",
      "10000/10000 [==============================] - 0s 41us/step - loss: 4.6532 - val_loss: 61.9320\n",
      "Epoch 21/50\n",
      "10000/10000 [==============================] - 0s 41us/step - loss: 4.3572 - val_loss: 46.6269\n",
      "Epoch 22/50\n",
      "10000/10000 [==============================] - 0s 41us/step - loss: 3.8726 - val_loss: 57.2699\n",
      "Epoch 23/50\n",
      "10000/10000 [==============================] - 0s 41us/step - loss: 3.1509 - val_loss: 44.4809\n",
      "Epoch 24/50\n",
      "10000/10000 [==============================] - 0s 41us/step - loss: 3.7526 - val_loss: 52.0245\n",
      "Epoch 25/50\n",
      "10000/10000 [==============================] - 0s 41us/step - loss: 2.7657 - val_loss: 52.2894\n",
      "Epoch 26/50\n",
      "10000/10000 [==============================] - 0s 41us/step - loss: 2.6241 - val_loss: 45.2854\n",
      "Epoch 27/50\n",
      "10000/10000 [==============================] - 0s 41us/step - loss: 3.4746 - val_loss: 44.8837\n",
      "Epoch 28/50\n",
      "10000/10000 [==============================] - 0s 41us/step - loss: 3.1333 - val_loss: 51.6029\n",
      "Epoch 29/50\n",
      "10000/10000 [==============================] - 0s 41us/step - loss: 3.0143 - val_loss: 50.9529\n",
      "Epoch 30/50\n",
      "10000/10000 [==============================] - 0s 41us/step - loss: 2.4885 - val_loss: 52.6174\n",
      "Epoch 31/50\n",
      "10000/10000 [==============================] - 0s 41us/step - loss: 2.9147 - val_loss: 43.9244\n",
      "Epoch 32/50\n",
      "10000/10000 [==============================] - 0s 41us/step - loss: 2.5039 - val_loss: 44.4871\n",
      "Epoch 33/50\n",
      "10000/10000 [==============================] - 0s 41us/step - loss: 1.9608 - val_loss: 50.5708\n",
      "Epoch 34/50\n",
      "10000/10000 [==============================] - 0s 42us/step - loss: 2.3766 - val_loss: 52.8507\n",
      "Epoch 35/50\n",
      "10000/10000 [==============================] - 0s 46us/step - loss: 2.3364 - val_loss: 43.6691\n",
      "Epoch 36/50\n",
      "10000/10000 [==============================] - 0s 43us/step - loss: 2.1859 - val_loss: 43.8251\n",
      "Epoch 37/50\n",
      "10000/10000 [==============================] - 0s 41us/step - loss: 2.6070 - val_loss: 44.4296\n",
      "Epoch 38/50\n",
      "10000/10000 [==============================] - 0s 41us/step - loss: 1.9040 - val_loss: 52.0330\n",
      "Epoch 39/50\n",
      "10000/10000 [==============================] - 0s 41us/step - loss: 2.1922 - val_loss: 51.9137\n",
      "Epoch 40/50\n",
      "10000/10000 [==============================] - 0s 41us/step - loss: 1.9034 - val_loss: 43.8922\n",
      "Epoch 41/50\n",
      "10000/10000 [==============================] - 0s 41us/step - loss: 1.7789 - val_loss: 51.4666\n",
      "Epoch 42/50\n",
      "10000/10000 [==============================] - 0s 41us/step - loss: 1.7634 - val_loss: 46.3875\n",
      "Epoch 43/50\n",
      "10000/10000 [==============================] - 0s 41us/step - loss: 1.9516 - val_loss: 52.4281\n",
      "Epoch 44/50\n",
      "10000/10000 [==============================] - 0s 41us/step - loss: 1.9669 - val_loss: 43.7814\n",
      "Epoch 45/50\n",
      "10000/10000 [==============================] - 0s 41us/step - loss: 1.4094 - val_loss: 44.1847\n",
      "Epoch 46/50\n",
      "10000/10000 [==============================] - 0s 41us/step - loss: 1.6506 - val_loss: 43.2068\n",
      "Epoch 47/50\n",
      "10000/10000 [==============================] - 0s 41us/step - loss: 1.4708 - val_loss: 46.8301\n",
      "Epoch 48/50\n",
      "10000/10000 [==============================] - 0s 41us/step - loss: 1.0820 - val_loss: 48.7210\n",
      "Epoch 49/50\n",
      "10000/10000 [==============================] - 0s 41us/step - loss: 1.5610 - val_loss: 49.4722\n",
      "Epoch 50/50\n",
      "10000/10000 [==============================] - 0s 41us/step - loss: 1.5141 - val_loss: 44.5849\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f9b7b08f940>"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp = mlp_model()\n",
    "mlp.compile(optimizer='adadelta', loss='mse')\n",
    "mlp.fit(graph_mats, graph_scores, epochs=50, batch_size=100, shuffle=True, validation_data=(val_mats, val_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 10000 samples, validate on 1000 samples\n",
      "Epoch 1/50\n",
      "10000/10000 [==============================] - 2s 186us/step - loss: 108.1851 - val_loss: 31.8376\n",
      "Epoch 2/50\n",
      "10000/10000 [==============================] - 1s 147us/step - loss: 43.0567 - val_loss: 35.6364\n",
      "Epoch 3/50\n",
      "10000/10000 [==============================] - 2s 155us/step - loss: 44.6972 - val_loss: 49.9159\n",
      "Epoch 4/50\n",
      "10000/10000 [==============================] - 1s 149us/step - loss: 42.1901 - val_loss: 32.7792\n",
      "Epoch 5/50\n",
      "10000/10000 [==============================] - 2s 153us/step - loss: 41.9236 - val_loss: 34.0634\n",
      "Epoch 6/50\n",
      "10000/10000 [==============================] - 2s 153us/step - loss: 40.4963 - val_loss: 36.6549\n",
      "Epoch 7/50\n",
      "10000/10000 [==============================] - 1s 149us/step - loss: 42.5076 - val_loss: 33.5008\n",
      "Epoch 8/50\n",
      "10000/10000 [==============================] - 2s 151us/step - loss: 38.3674 - val_loss: 35.6119\n",
      "Epoch 9/50\n",
      "10000/10000 [==============================] - 1s 149us/step - loss: 40.9159 - val_loss: 31.9349\n",
      "Epoch 10/50\n",
      "10000/10000 [==============================] - 2s 153us/step - loss: 38.7193 - val_loss: 40.3195\n",
      "Epoch 11/50\n",
      "10000/10000 [==============================] - 1s 149us/step - loss: 37.1714 - val_loss: 31.5997\n",
      "Epoch 12/50\n",
      "10000/10000 [==============================] - 2s 150us/step - loss: 37.3561 - val_loss: 31.5536\n",
      "Epoch 13/50\n",
      "10000/10000 [==============================] - 2s 153us/step - loss: 37.0386 - val_loss: 59.5006\n",
      "Epoch 14/50\n",
      "10000/10000 [==============================] - 2s 151us/step - loss: 38.1271 - val_loss: 32.0385\n",
      "Epoch 15/50\n",
      "10000/10000 [==============================] - 1s 148us/step - loss: 37.3547 - val_loss: 33.8712\n",
      "Epoch 16/50\n",
      "10000/10000 [==============================] - 1s 150us/step - loss: 35.7184 - val_loss: 45.5755\n",
      "Epoch 17/50\n",
      "10000/10000 [==============================] - 1s 148us/step - loss: 36.2124 - val_loss: 32.0485\n",
      "Epoch 18/50\n",
      "10000/10000 [==============================] - 1s 146us/step - loss: 37.5348 - val_loss: 31.7234\n",
      "Epoch 19/50\n",
      "10000/10000 [==============================] - 1s 148us/step - loss: 34.2632 - val_loss: 44.5868\n",
      "Epoch 20/50\n",
      "10000/10000 [==============================] - 1s 148us/step - loss: 35.4503 - val_loss: 32.4536\n",
      "Epoch 21/50\n",
      "10000/10000 [==============================] - 1s 147us/step - loss: 34.8288 - val_loss: 34.4077\n",
      "Epoch 22/50\n",
      "10000/10000 [==============================] - 1s 147us/step - loss: 35.0477 - val_loss: 36.5216\n",
      "Epoch 23/50\n",
      "10000/10000 [==============================] - 1s 147us/step - loss: 33.5291 - val_loss: 39.2193\n",
      "Epoch 24/50\n",
      "10000/10000 [==============================] - 1s 147us/step - loss: 34.2559 - val_loss: 32.3685\n",
      "Epoch 25/50\n",
      "10000/10000 [==============================] - 1s 147us/step - loss: 33.2727 - val_loss: 38.8569\n",
      "Epoch 26/50\n",
      "10000/10000 [==============================] - 1s 147us/step - loss: 34.6149 - val_loss: 35.2042\n",
      "Epoch 27/50\n",
      "10000/10000 [==============================] - 1s 149us/step - loss: 33.1112 - val_loss: 36.5828\n",
      "Epoch 28/50\n",
      "10000/10000 [==============================] - 2s 155us/step - loss: 32.3038 - val_loss: 45.9263\n",
      "Epoch 29/50\n",
      "10000/10000 [==============================] - 2s 152us/step - loss: 32.2878 - val_loss: 35.6244\n",
      "Epoch 30/50\n",
      "10000/10000 [==============================] - 1s 147us/step - loss: 31.9001 - val_loss: 35.9194\n",
      "Epoch 31/50\n",
      "10000/10000 [==============================] - 1s 147us/step - loss: 32.1992 - val_loss: 44.2263\n",
      "Epoch 32/50\n",
      "10000/10000 [==============================] - 1s 147us/step - loss: 31.6258 - val_loss: 39.3543\n",
      "Epoch 33/50\n",
      "10000/10000 [==============================] - 1s 150us/step - loss: 31.9105 - val_loss: 35.3056\n",
      "Epoch 34/50\n",
      "10000/10000 [==============================] - 1s 150us/step - loss: 30.6797 - val_loss: 44.3279\n",
      "Epoch 35/50\n",
      "10000/10000 [==============================] - 2s 151us/step - loss: 30.5027 - val_loss: 35.2795\n",
      "Epoch 36/50\n",
      "10000/10000 [==============================] - 2s 152us/step - loss: 29.3293 - val_loss: 38.2703\n",
      "Epoch 37/50\n",
      "10000/10000 [==============================] - 2s 151us/step - loss: 29.6925 - val_loss: 35.5690\n",
      "Epoch 38/50\n",
      "10000/10000 [==============================] - 2s 161us/step - loss: 28.7203 - val_loss: 38.2441\n",
      "Epoch 39/50\n",
      "10000/10000 [==============================] - 1s 147us/step - loss: 29.3901 - val_loss: 48.1416\n",
      "Epoch 40/50\n",
      "10000/10000 [==============================] - 1s 148us/step - loss: 27.8004 - val_loss: 38.5644\n",
      "Epoch 41/50\n",
      "10000/10000 [==============================] - 1s 148us/step - loss: 26.8764 - val_loss: 43.1487\n",
      "Epoch 42/50\n",
      "10000/10000 [==============================] - 1s 148us/step - loss: 26.9119 - val_loss: 40.2198\n",
      "Epoch 43/50\n",
      "10000/10000 [==============================] - 1s 148us/step - loss: 27.6904 - val_loss: 38.6593\n",
      "Epoch 44/50\n",
      "10000/10000 [==============================] - 1s 148us/step - loss: 26.2820 - val_loss: 41.3820\n",
      "Epoch 45/50\n",
      "10000/10000 [==============================] - 1s 147us/step - loss: 26.4454 - val_loss: 38.2726\n",
      "Epoch 46/50\n",
      "10000/10000 [==============================] - 1s 148us/step - loss: 25.6790 - val_loss: 39.3371\n",
      "Epoch 47/50\n",
      "10000/10000 [==============================] - 1s 147us/step - loss: 25.0141 - val_loss: 39.0801\n",
      "Epoch 48/50\n",
      "10000/10000 [==============================] - 1s 148us/step - loss: 24.8194 - val_loss: 41.4135\n",
      "Epoch 49/50\n",
      "10000/10000 [==============================] - 1s 149us/step - loss: 24.4775 - val_loss: 40.2782\n",
      "Epoch 50/50\n",
      "10000/10000 [==============================] - 1s 149us/step - loss: 24.4343 - val_loss: 40.5440\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f9b7b200f28>"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn = cnn_model()\n",
    "cnn.compile(optimizer='adadelta', loss='mse')\n",
    "cnn.fit(graph_mats, graph_scores, epochs=50, batch_size=100, shuffle=True, validation_data=(val_mats, val_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_8 (InputLayer)         (None, 100, 100, 1)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 100, 100, 32)      320       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2 (None, 50, 50, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 50, 50, 16)        4624      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2 (None, 25, 25, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 25, 25, 16)        2320      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2 (None, 13, 13, 16)        0         \n",
      "_________________________________________________________________\n",
      "flatten_7 (Flatten)          (None, 2704)              0         \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 32)                86560     \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 16)                528       \n",
      "=================================================================\n",
      "Total params: 94,352\n",
      "Trainable params: 94,352\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "cnn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
