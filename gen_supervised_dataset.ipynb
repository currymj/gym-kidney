{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "from gym_kidney import _solver\n",
    "from gym.utils import seeding\n",
    "from gym_kidney import models\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First: generate graphs somehow, according to the models.\n",
    "\n",
    "One dumb idea, give some a long number of ticks and others a short number of ticks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _default_model():\n",
    "    M = 128\n",
    "    K = 1024\n",
    "    K = 580\n",
    "    P = 0.05\n",
    "    P_A = 0.05\n",
    "    LEN = 3*K\n",
    "    MODEL = models.HomogeneousModel(M, K, P, P_A, LEN)\n",
    "    return MODEL\n",
    "\n",
    "DEFAULT_MODEL = _default_model()\n",
    "\n",
    "rng, seed = seeding.np_random(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_random_graph(model, rng, n_steps=300):\n",
    "    G = nx.DiGraph()\n",
    "    for i in range(n_steps):\n",
    "        G = model.arrive(G,rng)\n",
    "    return G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def relabel(G):\n",
    "    n_dd, n_ndd = 0, 0\n",
    "    d_dd, d_ndd = {}, {}\n",
    "\n",
    "    for u in G.nodes():\n",
    "        if G.node[u][\"ndd\"]:\n",
    "            d_ndd[u] = n_ndd\n",
    "            n_ndd += 1\n",
    "        else:\n",
    "            d_dd[u] = n_dd\n",
    "            n_dd += 1\n",
    "\n",
    "    return n_dd, n_ndd, d_dd, d_ndd\n",
    "\n",
    "def nx_to_ks(G):\n",
    "    n_dd, n_ndd, d_dd, d_ndd = relabel(G)\n",
    "\n",
    "    dd = _solver.Digraph(n_dd)\n",
    "    for u, v, d in G.edges(data = True):\n",
    "        if not G.node[u][\"ndd\"]:\n",
    "            dd.add_edge(\n",
    "                d[\"weight\"] if (\"weight\" in d) else 1.0,\n",
    "                dd.vs[d_dd[u]],\n",
    "                dd.vs[d_dd[v]])\n",
    "\n",
    "    ndds = [_solver.kidney_ndds.Ndd() for _ in range(n_ndd)]\n",
    "    for u, v, d in G.edges(data = True):\n",
    "        if G.node[u][\"ndd\"]:\n",
    "            edge = _solver.kidney_ndds.NddEdge(\n",
    "                dd.vs[d_dd[v]],\n",
    "                d[\"weight\"] if (\"weight\" in d) else 1.0)\n",
    "            ndds[d_ndd[u]].add_edge(edge)\n",
    "\n",
    "    return dd, ndds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def solve_graph(G, cycle_cap=3, chain_cap=3):\n",
    "    dd, ndd = nx_to_ks(G)\n",
    "    cfg = _solver.kidney_ip.OptConfig(\n",
    "            dd,\n",
    "            ndd,\n",
    "            cycle_cap,\n",
    "            chain_cap)\n",
    "    soln  = _solver.solve_kep(cfg, \"picef\")\n",
    "    rew_cycles = sum(map(lambda x: len(x), soln.cycles))\n",
    "    rew_chains = sum(map(lambda x: len(x.vtx_indices), soln.chains))\n",
    "    reward = rew_cycles + rew_chains\n",
    "    \n",
    "    return reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_graph_score_pair(rng):\n",
    "    gr = gen_random_graph(DEFAULT_MODEL, rng)\n",
    "    score = solve_graph(gr)\n",
    "    return (gr, score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [01:43<00:00, 96.31it/s]\n",
      "100%|██████████| 1000/1000 [00:10<00:00, 92.01it/s]\n"
     ]
    }
   ],
   "source": [
    "dataset = [make_graph_score_pair(rng) for _ in tqdm(range(10000))]\n",
    "validation_set = [make_graph_score_pair(rng) for _ in tqdm(range(1000))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adjmat(gr):\n",
    "    return nx.adjacency_matrix(gr).toarray().astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def zero_padded_adjmat(graph, size):\n",
    "    unpadded = adjmat(graph)\n",
    "    padded = np.zeros((size, size))\n",
    "    padded[0:unpadded.shape[0], 0:unpadded.shape[1]] = unpadded\n",
    "    padded = np.reshape(padded, (padded.shape[0], padded.shape[1], 1))\n",
    "    return padded\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "next step: tf really dumb mlp model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.keras\n",
    "from tensorflow.keras.layers import Input, Dense, Dropout, Flatten, MaxPooling2D, Conv2D\n",
    "from tensorflow.keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mlp_model(input_size=100):\n",
    "    input_im = Input(shape=(input_size, input_size, 1)) # may as well be compatible with cnn\n",
    "    flat = Flatten()(input_im)\n",
    "    l1 = Dense(100, activation='relu')(flat)\n",
    "    l2 = Dense(20, activation='relu')(l1)\n",
    "    output = Dense(1, activation='relu')(l2)\n",
    "    mlp_model = Model(input_im, output)\n",
    "    return mlp_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cnn_model(input_size=100):\n",
    "    input_im = Input(shape=(input_size, input_size,1))\n",
    "    layer = Conv2D(32, (3, 3), activation='relu', padding='same')(input_im)\n",
    "    layer = MaxPooling2D((2, 2), padding='same')(layer)\n",
    "    layer = Conv2D(16, (3, 3), activation='relu', padding='same')(layer)\n",
    "    layer = MaxPooling2D((2, 2), padding='same')(layer)\n",
    "    layer = Conv2D(16, (3, 3), activation='relu', padding='same')(layer)\n",
    "    layer = MaxPooling2D((2, 2), padding='same')(layer)\n",
    "    layer = Flatten()(layer)\n",
    "    layer = Dense(32, activation='relu')(layer)\n",
    "    output = Dense(1, activation='relu')(layer)\n",
    "    cnn_model = Model(input_im, output)\n",
    "    return cnn_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_9 (InputLayer)         (None, 100, 100, 1)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 100, 100, 32)      320       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_9 (MaxPooling2 (None, 50, 50, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_10 (Conv2D)           (None, 50, 50, 16)        4624      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_10 (MaxPooling (None, 25, 25, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_11 (Conv2D)           (None, 25, 25, 16)        2320      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_11 (MaxPooling (None, 13, 13, 16)        0         \n",
      "_________________________________________________________________\n",
      "flatten_8 (Flatten)          (None, 2704)              0         \n",
      "_________________________________________________________________\n",
      "dense_21 (Dense)             (None, 32)                86560     \n",
      "_________________________________________________________________\n",
      "dense_22 (Dense)             (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 93,857\n",
      "Trainable params: 93,857\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "cnn_model().summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_6 (InputLayer)         (None, 100, 100, 1)       0         \n",
      "_________________________________________________________________\n",
      "flatten_5 (Flatten)          (None, 10000)             0         \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 100)               1000100   \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 20)                2020      \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 1)                 21        \n",
      "=================================================================\n",
      "Total params: 1,002,141\n",
      "Trainable params: 1,002,141\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "mlp_model().summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_mats = np.stack([zero_padded_adjmat(g, 100) for g, _ in dataset])\n",
    "graph_scores = np.expand_dims(np.stack([x for _, x in dataset]), axis=1).astype('float32')\n",
    "\n",
    "val_mats = np.stack([zero_padded_adjmat(g, 100) for g, _ in validation_set])\n",
    "val_scores = np.expand_dims(np.stack([x for _, x in validation_set]), axis=1).astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 10000 samples, validate on 1000 samples\n",
      "Epoch 1/50\n",
      "10000/10000 [==============================] - 1s 67us/step - loss: 79.6723 - val_loss: 34.2367\n",
      "Epoch 2/50\n",
      "10000/10000 [==============================] - 0s 40us/step - loss: 31.0945 - val_loss: 35.4946\n",
      "Epoch 3/50\n",
      "10000/10000 [==============================] - 0s 41us/step - loss: 27.1537 - val_loss: 40.9094\n",
      "Epoch 4/50\n",
      "10000/10000 [==============================] - 0s 41us/step - loss: 23.8659 - val_loss: 41.9874\n",
      "Epoch 5/50\n",
      "10000/10000 [==============================] - 0s 41us/step - loss: 18.0754 - val_loss: 47.8495\n",
      "Epoch 6/50\n",
      "10000/10000 [==============================] - 0s 41us/step - loss: 12.2546 - val_loss: 50.8657\n",
      "Epoch 7/50\n",
      "10000/10000 [==============================] - 0s 41us/step - loss: 9.5404 - val_loss: 51.3274\n",
      "Epoch 8/50\n",
      "10000/10000 [==============================] - 0s 42us/step - loss: 9.3253 - val_loss: 58.3344\n",
      "Epoch 9/50\n",
      "10000/10000 [==============================] - 0s 41us/step - loss: 8.1976 - val_loss: 46.2212\n",
      "Epoch 10/50\n",
      "10000/10000 [==============================] - 0s 41us/step - loss: 7.8441 - val_loss: 46.2443\n",
      "Epoch 11/50\n",
      "10000/10000 [==============================] - 0s 41us/step - loss: 7.1912 - val_loss: 47.5968\n",
      "Epoch 12/50\n",
      "10000/10000 [==============================] - 0s 41us/step - loss: 5.3722 - val_loss: 64.2285\n",
      "Epoch 13/50\n",
      "10000/10000 [==============================] - 0s 42us/step - loss: 6.8320 - val_loss: 59.6221\n",
      "Epoch 14/50\n",
      "10000/10000 [==============================] - 0s 41us/step - loss: 5.9355 - val_loss: 46.5091\n",
      "Epoch 15/50\n",
      "10000/10000 [==============================] - 0s 41us/step - loss: 5.3262 - val_loss: 58.0585\n",
      "Epoch 16/50\n",
      "10000/10000 [==============================] - 0s 41us/step - loss: 5.6258 - val_loss: 58.1062\n",
      "Epoch 17/50\n",
      "10000/10000 [==============================] - 0s 41us/step - loss: 4.9626 - val_loss: 47.9548\n",
      "Epoch 18/50\n",
      "10000/10000 [==============================] - 0s 41us/step - loss: 4.8155 - val_loss: 46.1798\n",
      "Epoch 19/50\n",
      "10000/10000 [==============================] - 0s 41us/step - loss: 4.2920 - val_loss: 52.7111\n",
      "Epoch 20/50\n",
      "10000/10000 [==============================] - 0s 41us/step - loss: 4.6532 - val_loss: 61.9320\n",
      "Epoch 21/50\n",
      "10000/10000 [==============================] - 0s 41us/step - loss: 4.3572 - val_loss: 46.6269\n",
      "Epoch 22/50\n",
      "10000/10000 [==============================] - 0s 41us/step - loss: 3.8726 - val_loss: 57.2699\n",
      "Epoch 23/50\n",
      "10000/10000 [==============================] - 0s 41us/step - loss: 3.1509 - val_loss: 44.4809\n",
      "Epoch 24/50\n",
      "10000/10000 [==============================] - 0s 41us/step - loss: 3.7526 - val_loss: 52.0245\n",
      "Epoch 25/50\n",
      "10000/10000 [==============================] - 0s 41us/step - loss: 2.7657 - val_loss: 52.2894\n",
      "Epoch 26/50\n",
      "10000/10000 [==============================] - 0s 41us/step - loss: 2.6241 - val_loss: 45.2854\n",
      "Epoch 27/50\n",
      "10000/10000 [==============================] - 0s 41us/step - loss: 3.4746 - val_loss: 44.8837\n",
      "Epoch 28/50\n",
      "10000/10000 [==============================] - 0s 41us/step - loss: 3.1333 - val_loss: 51.6029\n",
      "Epoch 29/50\n",
      "10000/10000 [==============================] - 0s 41us/step - loss: 3.0143 - val_loss: 50.9529\n",
      "Epoch 30/50\n",
      "10000/10000 [==============================] - 0s 41us/step - loss: 2.4885 - val_loss: 52.6174\n",
      "Epoch 31/50\n",
      "10000/10000 [==============================] - 0s 41us/step - loss: 2.9147 - val_loss: 43.9244\n",
      "Epoch 32/50\n",
      "10000/10000 [==============================] - 0s 41us/step - loss: 2.5039 - val_loss: 44.4871\n",
      "Epoch 33/50\n",
      "10000/10000 [==============================] - 0s 41us/step - loss: 1.9608 - val_loss: 50.5708\n",
      "Epoch 34/50\n",
      "10000/10000 [==============================] - 0s 42us/step - loss: 2.3766 - val_loss: 52.8507\n",
      "Epoch 35/50\n",
      "10000/10000 [==============================] - 0s 46us/step - loss: 2.3364 - val_loss: 43.6691\n",
      "Epoch 36/50\n",
      "10000/10000 [==============================] - 0s 43us/step - loss: 2.1859 - val_loss: 43.8251\n",
      "Epoch 37/50\n",
      "10000/10000 [==============================] - 0s 41us/step - loss: 2.6070 - val_loss: 44.4296\n",
      "Epoch 38/50\n",
      "10000/10000 [==============================] - 0s 41us/step - loss: 1.9040 - val_loss: 52.0330\n",
      "Epoch 39/50\n",
      "10000/10000 [==============================] - 0s 41us/step - loss: 2.1922 - val_loss: 51.9137\n",
      "Epoch 40/50\n",
      "10000/10000 [==============================] - 0s 41us/step - loss: 1.9034 - val_loss: 43.8922\n",
      "Epoch 41/50\n",
      "10000/10000 [==============================] - 0s 41us/step - loss: 1.7789 - val_loss: 51.4666\n",
      "Epoch 42/50\n",
      "10000/10000 [==============================] - 0s 41us/step - loss: 1.7634 - val_loss: 46.3875\n",
      "Epoch 43/50\n",
      "10000/10000 [==============================] - 0s 41us/step - loss: 1.9516 - val_loss: 52.4281\n",
      "Epoch 44/50\n",
      "10000/10000 [==============================] - 0s 41us/step - loss: 1.9669 - val_loss: 43.7814\n",
      "Epoch 45/50\n",
      "10000/10000 [==============================] - 0s 41us/step - loss: 1.4094 - val_loss: 44.1847\n",
      "Epoch 46/50\n",
      "10000/10000 [==============================] - 0s 41us/step - loss: 1.6506 - val_loss: 43.2068\n",
      "Epoch 47/50\n",
      "10000/10000 [==============================] - 0s 41us/step - loss: 1.4708 - val_loss: 46.8301\n",
      "Epoch 48/50\n",
      "10000/10000 [==============================] - 0s 41us/step - loss: 1.0820 - val_loss: 48.7210\n",
      "Epoch 49/50\n",
      "10000/10000 [==============================] - 0s 41us/step - loss: 1.5610 - val_loss: 49.4722\n",
      "Epoch 50/50\n",
      "10000/10000 [==============================] - 0s 41us/step - loss: 1.5141 - val_loss: 44.5849\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f9b7b08f940>"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp = mlp_model()\n",
    "mlp.compile(optimizer='adadelta', loss='mse')\n",
    "mlp.fit(graph_mats, graph_scores, epochs=50, batch_size=100, shuffle=True, validation_data=(val_mats, val_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 10000 samples, validate on 1000 samples\n",
      "Epoch 1/50\n",
      "10000/10000 [==============================] - 2s 186us/step - loss: 108.1851 - val_loss: 31.8376\n",
      "Epoch 2/50\n",
      "10000/10000 [==============================] - 1s 147us/step - loss: 43.0567 - val_loss: 35.6364\n",
      "Epoch 3/50\n",
      "10000/10000 [==============================] - 2s 155us/step - loss: 44.6972 - val_loss: 49.9159\n",
      "Epoch 4/50\n",
      "10000/10000 [==============================] - 1s 149us/step - loss: 42.1901 - val_loss: 32.7792\n",
      "Epoch 5/50\n",
      "10000/10000 [==============================] - 2s 153us/step - loss: 41.9236 - val_loss: 34.0634\n",
      "Epoch 6/50\n",
      "10000/10000 [==============================] - 2s 153us/step - loss: 40.4963 - val_loss: 36.6549\n",
      "Epoch 7/50\n",
      "10000/10000 [==============================] - 1s 149us/step - loss: 42.5076 - val_loss: 33.5008\n",
      "Epoch 8/50\n",
      "10000/10000 [==============================] - 2s 151us/step - loss: 38.3674 - val_loss: 35.6119\n",
      "Epoch 9/50\n",
      "10000/10000 [==============================] - 1s 149us/step - loss: 40.9159 - val_loss: 31.9349\n",
      "Epoch 10/50\n",
      "10000/10000 [==============================] - 2s 153us/step - loss: 38.7193 - val_loss: 40.3195\n",
      "Epoch 11/50\n",
      "10000/10000 [==============================] - 1s 149us/step - loss: 37.1714 - val_loss: 31.5997\n",
      "Epoch 12/50\n",
      "10000/10000 [==============================] - 2s 150us/step - loss: 37.3561 - val_loss: 31.5536\n",
      "Epoch 13/50\n",
      "10000/10000 [==============================] - 2s 153us/step - loss: 37.0386 - val_loss: 59.5006\n",
      "Epoch 14/50\n",
      "10000/10000 [==============================] - 2s 151us/step - loss: 38.1271 - val_loss: 32.0385\n",
      "Epoch 15/50\n",
      "10000/10000 [==============================] - 1s 148us/step - loss: 37.3547 - val_loss: 33.8712\n",
      "Epoch 16/50\n",
      "10000/10000 [==============================] - 1s 150us/step - loss: 35.7184 - val_loss: 45.5755\n",
      "Epoch 17/50\n",
      "10000/10000 [==============================] - 1s 148us/step - loss: 36.2124 - val_loss: 32.0485\n",
      "Epoch 18/50\n",
      "10000/10000 [==============================] - 1s 146us/step - loss: 37.5348 - val_loss: 31.7234\n",
      "Epoch 19/50\n",
      "10000/10000 [==============================] - 1s 148us/step - loss: 34.2632 - val_loss: 44.5868\n",
      "Epoch 20/50\n",
      "10000/10000 [==============================] - 1s 148us/step - loss: 35.4503 - val_loss: 32.4536\n",
      "Epoch 21/50\n",
      "10000/10000 [==============================] - 1s 147us/step - loss: 34.8288 - val_loss: 34.4077\n",
      "Epoch 22/50\n",
      "10000/10000 [==============================] - 1s 147us/step - loss: 35.0477 - val_loss: 36.5216\n",
      "Epoch 23/50\n",
      "10000/10000 [==============================] - 1s 147us/step - loss: 33.5291 - val_loss: 39.2193\n",
      "Epoch 24/50\n",
      "10000/10000 [==============================] - 1s 147us/step - loss: 34.2559 - val_loss: 32.3685\n",
      "Epoch 25/50\n",
      "10000/10000 [==============================] - 1s 147us/step - loss: 33.2727 - val_loss: 38.8569\n",
      "Epoch 26/50\n",
      "10000/10000 [==============================] - 1s 147us/step - loss: 34.6149 - val_loss: 35.2042\n",
      "Epoch 27/50\n",
      "10000/10000 [==============================] - 1s 149us/step - loss: 33.1112 - val_loss: 36.5828\n",
      "Epoch 28/50\n",
      "10000/10000 [==============================] - 2s 155us/step - loss: 32.3038 - val_loss: 45.9263\n",
      "Epoch 29/50\n",
      "10000/10000 [==============================] - 2s 152us/step - loss: 32.2878 - val_loss: 35.6244\n",
      "Epoch 30/50\n",
      "10000/10000 [==============================] - 1s 147us/step - loss: 31.9001 - val_loss: 35.9194\n",
      "Epoch 31/50\n",
      "10000/10000 [==============================] - 1s 147us/step - loss: 32.1992 - val_loss: 44.2263\n",
      "Epoch 32/50\n",
      "10000/10000 [==============================] - 1s 147us/step - loss: 31.6258 - val_loss: 39.3543\n",
      "Epoch 33/50\n",
      "10000/10000 [==============================] - 1s 150us/step - loss: 31.9105 - val_loss: 35.3056\n",
      "Epoch 34/50\n",
      "10000/10000 [==============================] - 1s 150us/step - loss: 30.6797 - val_loss: 44.3279\n",
      "Epoch 35/50\n",
      "10000/10000 [==============================] - 2s 151us/step - loss: 30.5027 - val_loss: 35.2795\n",
      "Epoch 36/50\n",
      "10000/10000 [==============================] - 2s 152us/step - loss: 29.3293 - val_loss: 38.2703\n",
      "Epoch 37/50\n",
      "10000/10000 [==============================] - 2s 151us/step - loss: 29.6925 - val_loss: 35.5690\n",
      "Epoch 38/50\n",
      "10000/10000 [==============================] - 2s 161us/step - loss: 28.7203 - val_loss: 38.2441\n",
      "Epoch 39/50\n",
      "10000/10000 [==============================] - 1s 147us/step - loss: 29.3901 - val_loss: 48.1416\n",
      "Epoch 40/50\n",
      "10000/10000 [==============================] - 1s 148us/step - loss: 27.8004 - val_loss: 38.5644\n",
      "Epoch 41/50\n",
      "10000/10000 [==============================] - 1s 148us/step - loss: 26.8764 - val_loss: 43.1487\n",
      "Epoch 42/50\n",
      "10000/10000 [==============================] - 1s 148us/step - loss: 26.9119 - val_loss: 40.2198\n",
      "Epoch 43/50\n",
      "10000/10000 [==============================] - 1s 148us/step - loss: 27.6904 - val_loss: 38.6593\n",
      "Epoch 44/50\n",
      "10000/10000 [==============================] - 1s 148us/step - loss: 26.2820 - val_loss: 41.3820\n",
      "Epoch 45/50\n",
      "10000/10000 [==============================] - 1s 147us/step - loss: 26.4454 - val_loss: 38.2726\n",
      "Epoch 46/50\n",
      "10000/10000 [==============================] - 1s 148us/step - loss: 25.6790 - val_loss: 39.3371\n",
      "Epoch 47/50\n",
      "10000/10000 [==============================] - 1s 147us/step - loss: 25.0141 - val_loss: 39.0801\n",
      "Epoch 48/50\n",
      "10000/10000 [==============================] - 1s 148us/step - loss: 24.8194 - val_loss: 41.4135\n",
      "Epoch 49/50\n",
      "10000/10000 [==============================] - 1s 149us/step - loss: 24.4775 - val_loss: 40.2782\n",
      "Epoch 50/50\n",
      "10000/10000 [==============================] - 1s 149us/step - loss: 24.4343 - val_loss: 40.5440\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f9b7b200f28>"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn = cnn_model()\n",
    "cnn.compile(optimizer='adadelta', loss='mse')\n",
    "cnn.fit(graph_mats, graph_scores, epochs=50, batch_size=100, shuffle=True, validation_data=(val_mats, val_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_8 (InputLayer)         (None, 100, 100, 1)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 100, 100, 32)      320       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2 (None, 50, 50, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 50, 50, 16)        4624      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2 (None, 25, 25, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 25, 25, 16)        2320      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2 (None, 13, 13, 16)        0         \n",
      "_________________________________________________________________\n",
      "flatten_7 (Flatten)          (None, 2704)              0         \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 32)                86560     \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 16)                528       \n",
      "=================================================================\n",
      "Total params: 94,352\n",
      "Trainable params: 94,352\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "cnn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
